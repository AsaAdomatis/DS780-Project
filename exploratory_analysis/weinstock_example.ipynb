{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.insert(1, '..')\n",
    "os.chdir('..')\n",
    "\n",
    "from data_formatters.weinstock2016 import *\n",
    "from dataset import TSDataset\n",
    "from conf import Conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code walk-through\n",
    "\n",
    "The major parts of the code that need to be defined for each data set are:\n",
    "1. config file in `.yaml` format,\n",
    "2. data formatter script.\n",
    "\n",
    "For now, you can study the `.yaml` files in the `./conf` folder for a look of what a config file should feel like. You can skip the hyperparam defintions and the model parameters. The main focus would be on defining the dataset parameters. \n",
    "\n",
    "We do not intereact with `.yaml` in a direct way but instead though `Conf` class, which handles the following:\n",
    "1. defines some defaults if not specified in `.yaml`,\n",
    "2. sets save paths,\n",
    "3. allows for nice colored printing.\n",
    "\n",
    "Technically, we could doo all of this in the `.yaml` file directly. However, then every time we re-run the experiment, we would have to manually modify the `.yaml` file to reset save paths and redefine some variables, which would be inconvenient.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the config file, setting the experiment name, and the seed for random pre-processing parts (like splitting)\n",
    "cnf = Conf(conf_file_path='./conf/weinstock.yaml', seed=15, exp_name=\"Weinstock\", log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets print out the config file\n",
    "print(f'\\nDefault configuration parameters: \\n{cnf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to the data formatter. This is the part that should handle:\n",
    "1. loading the data and setting types,\n",
    "2. **interpolating** segments,\n",
    "3. splitting the data into train / val / test sets,\n",
    "4. setting scalers and encoders for numerical / categorical variables resp.\n",
    "\n",
    "**Note:** the data formatter is ultimately what handles **all pre-processing** steps. We must be very careful in handling it and verifying that everrything happens correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the data fromatter directly\n",
    "data_formatter = WeinstockFormatter(cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data inside the data formatter\n",
    "counter = 0\n",
    "for id_segment, df in data_formatter.data.groupby('id_segment'):\n",
    "    # print(id_segment)\n",
    "    df.plot(x='time', y='gl', title=f'Segment {id_segment}')\n",
    "    plt.show()\n",
    "    counter += 1\n",
    "    if(counter == 5): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see train, val, and test numbers\n",
    "print(f'Train / val / test indices: {len(data_formatter.train_idx)}, {len(data_formatter.val_idx)}, {len(data_formatter.test_idx)}')\n",
    "# let's see proprtions\n",
    "print(f'Train / val / test proportions: {len(data_formatter.train_idx) / len(data_formatter.data)}, {len(data_formatter.val_idx) / len(data_formatter.data)}, {len(data_formatter.test_idx) / len(data_formatter.data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_formatter.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's work with the `TSDataset` class. This is the main part of the code as it aligns all of our previous steps. In the end, it is the `TSDataset` that is going to call the splitters, scalers, and encoders. **Importatnly** the model is only going to interact with the data through this class. \n",
    "\n",
    "**NOTE:** for each train, validation, and test set we must specify a separate data set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to pass our data formatter and the config file to the TSDataset class\n",
    "train_dataset = TSDataset(cnf, data_formatter, split='train')\n",
    "val_dataset = TSDataset(cnf, data_formatter, split='val')\n",
    "test_dataset = TSDataset(cnf, data_formatter, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's see how we can sample minibatches from our dataset that we can then pass to the model to train on\n",
    "for i in range(10):\n",
    "    # 192 x ['power_usage', 'hour', 'day_of_week', 'hours_from_start', 'categorical_id']\n",
    "    x = train_dataset[i]['inputs']\n",
    "    # 24 x ['power_usage']\n",
    "    y = train_dataset[i]['outputs']\n",
    "    print(f'Example #{i}: x.shape={x.shape}, y.shape={y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    # 192 x ['power_usage', 'hour', 'day_of_week', 'hours_from_start', 'categorical_id']\n",
    "    x = test_dataset[i]['inputs']\n",
    "    print(x[0, :])\n",
    "    # 24 x ['power_usage']\n",
    "    y = test_dataset[i]['outputs']\n",
    "\n",
    "    # plt.plot(x[:, 5])\n",
    "    plt.plot(y)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
