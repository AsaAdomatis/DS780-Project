{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from original example.ipynb\n",
    "import yaml\n",
    "from data_formatter.base import DataFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Loading column definition...\n",
      "Checking column definition...\n",
      "Loading data...\n",
      "Dropping columns / rows...\n",
      "Checking for NA values...\n",
      "Setting data types...\n",
      "Dropping columns / rows...\n",
      "Encoding data...\n",
      "\tUpdated column definition:\n",
      "\t\tid: REAL_VALUED (ID)\n",
      "\t\ttime: DATE (TIME)\n",
      "\t\tgl: REAL_VALUED (TARGET)\n",
      "\t\tAge: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tBMI: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tA1C: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tFBG: REAL_VALUED (STATIC_INPUT)\n",
      "\t\togtt.2hr: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tinsulin: REAL_VALUED (STATIC_INPUT)\n",
      "\t\ths.CRP: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tTchol: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tTrg: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tHDL: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tLDL: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmean_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tsd_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\trange_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmin_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmax_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tquartile.25_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmedian_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tquartile.75_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmean_slope: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmax_slope: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumber_Random140: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumber_Random200: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tpercent_below.80: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tse_glucose_mean: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumGE: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmage: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tj_index: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tIQR: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmodd: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tdistance_traveled: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tcoef_variation: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumber_Random140_normByDays: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumber_Random200_normByDays: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumGE_normByDays: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tdistance_traveled_normByDays: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tdiagnosis: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tfreq_low: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tfreq_moderate: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tfreq_severe: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tglucotype: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tHeight: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tWeight: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tInsulin_rate_dd: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tperc_cgm_prediabetic_range: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tperc_cgm_diabetic_range: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tSSPG: REAL_VALUED (STATIC_INPUT)\n",
      "\t\ttime_year: REAL_VALUED (KNOWN_INPUT)\n",
      "\t\ttime_month: REAL_VALUED (KNOWN_INPUT)\n",
      "\t\ttime_day: REAL_VALUED (KNOWN_INPUT)\n",
      "\t\ttime_hour: REAL_VALUED (KNOWN_INPUT)\n",
      "\t\ttime_minute: REAL_VALUED (KNOWN_INPUT)\n",
      "Interpolating data...\n",
      "\tDropped segments: 160\n",
      "\tExtracted segments: 152\n",
      "\tInterpolated values: 8003\n",
      "\tPercent of values interpolated: 8.57%\n",
      "Splitting data...\n",
      "\tTrain: 62461 (61.57%)\n",
      "\tVal: 12357 (12.18%)\n",
      "\tTest: 16517 (16.28%)\n",
      "\tTest OOD: 10113 (9.97%)\n",
      "Scaling data...\n",
      "\tNo scaling applied\n",
      "Data formatting complete.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# all fro original example.ipynb, but with a different dataset\n",
    "import yaml\n",
    "from data_formatter.base import DataFormatter\n",
    "\n",
    "# load config file\n",
    "dataset = 'hall' # changed from 'weinstock' dataset\n",
    "with open(f'./config/{dataset}.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "# create data formatter: loads the data and performs the pre-processing\n",
    "formatter = DataFormatter(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is loaded and pre-processed, we can access the underlying tables via the following set of commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>gl</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A1C</th>\n",
       "      <th>FBG</th>\n",
       "      <th>ogtt.2hr</th>\n",
       "      <th>insulin</th>\n",
       "      <th>hs.CRP</th>\n",
       "      <th>...</th>\n",
       "      <th>Insulin_rate_dd</th>\n",
       "      <th>perc_cgm_prediabetic_range</th>\n",
       "      <th>perc_cgm_diabetic_range</th>\n",
       "      <th>SSPG</th>\n",
       "      <th>time_year</th>\n",
       "      <th>time_month</th>\n",
       "      <th>time_day</th>\n",
       "      <th>time_hour</th>\n",
       "      <th>time_minute</th>\n",
       "      <th>id_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-03 03:42:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-03 03:47:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-03 03:52:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-03 03:57:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-03 04:02:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time   id    gl   Age        BMI  A1C    FBG  ogtt.2hr  \\\n",
       "0 2014-02-03 03:42:00  0.0  93.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "1 2014-02-03 03:47:00  0.0  93.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "2 2014-02-03 03:52:00  0.0  93.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "3 2014-02-03 03:57:00  0.0  95.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "4 2014-02-03 04:02:00  0.0  96.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "\n",
       "   insulin  hs.CRP  ...  Insulin_rate_dd  perc_cgm_prediabetic_range  \\\n",
       "0      9.0     0.3  ...           0.1015                    0.190404   \n",
       "1      9.0     0.3  ...           0.1015                    0.190404   \n",
       "2      9.0     0.3  ...           0.1015                    0.190404   \n",
       "3      9.0     0.3  ...           0.1015                    0.190404   \n",
       "4      9.0     0.3  ...           0.1015                    0.190404   \n",
       "\n",
       "   perc_cgm_diabetic_range  SSPG  time_year  time_month  time_day  time_hour  \\\n",
       "0                 0.026211  91.0     2014.0         2.0       3.0        3.0   \n",
       "1                 0.026211  91.0     2014.0         2.0       3.0        3.0   \n",
       "2                 0.026211  91.0     2014.0         2.0       3.0        3.0   \n",
       "3                 0.026211  91.0     2014.0         2.0       3.0        3.0   \n",
       "4                 0.026211  91.0     2014.0         2.0       3.0        4.0   \n",
       "\n",
       "   time_minute  id_segment  \n",
       "0         42.0           0  \n",
       "1         47.0           0  \n",
       "2         52.0           0  \n",
       "3         57.0           0  \n",
       "4          2.0           0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full data, unscaled\n",
    "formatter.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>gl</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A1C</th>\n",
       "      <th>FBG</th>\n",
       "      <th>ogtt.2hr</th>\n",
       "      <th>insulin</th>\n",
       "      <th>hs.CRP</th>\n",
       "      <th>...</th>\n",
       "      <th>Insulin_rate_dd</th>\n",
       "      <th>perc_cgm_prediabetic_range</th>\n",
       "      <th>perc_cgm_diabetic_range</th>\n",
       "      <th>SSPG</th>\n",
       "      <th>time_year</th>\n",
       "      <th>time_month</th>\n",
       "      <th>time_day</th>\n",
       "      <th>time_hour</th>\n",
       "      <th>time_minute</th>\n",
       "      <th>id_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-03 03:42:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-03 03:47:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-03 03:52:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-03 03:57:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-03 04:02:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.190404</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time   id    gl   Age        BMI  A1C    FBG  ogtt.2hr  \\\n",
       "0 2014-02-03 03:42:00  0.0  93.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "1 2014-02-03 03:47:00  0.0  93.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "2 2014-02-03 03:52:00  0.0  93.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "3 2014-02-03 03:57:00  0.0  95.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "4 2014-02-03 04:02:00  0.0  96.0  59.0  21.700001  6.7  109.0     205.0   \n",
       "\n",
       "   insulin  hs.CRP  ...  Insulin_rate_dd  perc_cgm_prediabetic_range  \\\n",
       "0      9.0     0.3  ...           0.1015                    0.190404   \n",
       "1      9.0     0.3  ...           0.1015                    0.190404   \n",
       "2      9.0     0.3  ...           0.1015                    0.190404   \n",
       "3      9.0     0.3  ...           0.1015                    0.190404   \n",
       "4      9.0     0.3  ...           0.1015                    0.190404   \n",
       "\n",
       "   perc_cgm_diabetic_range  SSPG  time_year  time_month  time_day  time_hour  \\\n",
       "0                 0.026211  91.0     2014.0         2.0       3.0        3.0   \n",
       "1                 0.026211  91.0     2014.0         2.0       3.0        3.0   \n",
       "2                 0.026211  91.0     2014.0         2.0       3.0        3.0   \n",
       "3                 0.026211  91.0     2014.0         2.0       3.0        3.0   \n",
       "4                 0.026211  91.0     2014.0         2.0       3.0        4.0   \n",
       "\n",
       "   time_minute  id_segment  \n",
       "0         42.0           0  \n",
       "1         47.0           0  \n",
       "2         52.0           0  \n",
       "3         57.0           0  \n",
       "4          2.0           0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data, scaled\n",
    "formatter.train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>gl</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A1C</th>\n",
       "      <th>FBG</th>\n",
       "      <th>ogtt.2hr</th>\n",
       "      <th>insulin</th>\n",
       "      <th>hs.CRP</th>\n",
       "      <th>...</th>\n",
       "      <th>Insulin_rate_dd</th>\n",
       "      <th>perc_cgm_prediabetic_range</th>\n",
       "      <th>perc_cgm_diabetic_range</th>\n",
       "      <th>SSPG</th>\n",
       "      <th>time_year</th>\n",
       "      <th>time_month</th>\n",
       "      <th>time_day</th>\n",
       "      <th>time_hour</th>\n",
       "      <th>time_minute</th>\n",
       "      <th>id_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>2015-04-02 13:33:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>5.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>2015-04-02 13:38:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>5.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>2015-04-02 13:43:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>5.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>2015-04-02 13:48:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>5.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>2015-04-02 13:53:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>5.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time   id     gl   Age        BMI  A1C   FBG  ogtt.2hr  \\\n",
       "3540 2015-04-02 13:33:00  2.0  129.0  50.0  27.299999  5.2  91.0     121.0   \n",
       "3541 2015-04-02 13:38:00  2.0  131.0  50.0  27.299999  5.2  91.0     121.0   \n",
       "3542 2015-04-02 13:43:00  2.0  132.0  50.0  27.299999  5.2  91.0     121.0   \n",
       "3543 2015-04-02 13:48:00  2.0  137.0  50.0  27.299999  5.2  91.0     121.0   \n",
       "3544 2015-04-02 13:53:00  2.0  135.0  50.0  27.299999  5.2  91.0     121.0   \n",
       "\n",
       "      insulin  hs.CRP  ...  Insulin_rate_dd  perc_cgm_prediabetic_range  \\\n",
       "3540      4.0     4.4  ...             -1.0                    0.071429   \n",
       "3541      4.0     4.4  ...             -1.0                    0.071429   \n",
       "3542      4.0     4.4  ...             -1.0                    0.071429   \n",
       "3543      4.0     4.4  ...             -1.0                    0.071429   \n",
       "3544      4.0     4.4  ...             -1.0                    0.071429   \n",
       "\n",
       "      perc_cgm_diabetic_range  SSPG  time_year  time_month  time_day  \\\n",
       "3540                 0.001544  75.0     2015.0         4.0       2.0   \n",
       "3541                 0.001544  75.0     2015.0         4.0       2.0   \n",
       "3542                 0.001544  75.0     2015.0         4.0       2.0   \n",
       "3543                 0.001544  75.0     2015.0         4.0       2.0   \n",
       "3544                 0.001544  75.0     2015.0         4.0       2.0   \n",
       "\n",
       "      time_hour  time_minute  id_segment  \n",
       "3540       13.0         33.0           5  \n",
       "3541       13.0         38.0           5  \n",
       "3542       13.0         43.0           5  \n",
       "3543       13.0         48.0           5  \n",
       "3544       13.0         53.0           5  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out-of-distribution test data, scaled (OOD meaning test set differs significantly from training)\n",
    "formatter.test_data[formatter.test_data.index.isin(formatter.test_idx_ood)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_test_entries_train</th>\n",
       "      <th>max_time</th>\n",
       "      <th>num_test_entries_test</th>\n",
       "      <th>min_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1386.0</td>\n",
       "      <td>2015-04-01 07:08:00</td>\n",
       "      <td>336</td>\n",
       "      <td>2015-04-01 11:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1386.0</td>\n",
       "      <td>2015-11-29 04:37:00</td>\n",
       "      <td>336</td>\n",
       "      <td>2015-11-29 08:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1769</td>\n",
       "      <td>2015-04-02 13:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>2016-01-18 09:33:00</td>\n",
       "      <td>336</td>\n",
       "      <td>2016-01-18 13:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>740.0</td>\n",
       "      <td>2016-01-31 10:02:00</td>\n",
       "      <td>208</td>\n",
       "      <td>2016-02-02 12:37:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_test_entries_train            max_time  num_test_entries_test  \\\n",
       "id                                                                       \n",
       "0.0                  1386.0 2015-04-01 07:08:00                    336   \n",
       "1.0                  1386.0 2015-11-29 04:37:00                    336   \n",
       "2.0                     NaN                 NaT                   1769   \n",
       "3.0                  1400.0 2016-01-18 09:33:00                    336   \n",
       "4.0                   740.0 2016-01-31 10:02:00                    208   \n",
       "\n",
       "               min_time  \n",
       "id                       \n",
       "0.0 2015-04-01 11:13:00  \n",
       "1.0 2015-11-29 08:42:00  \n",
       "2.0 2015-04-02 13:33:00  \n",
       "3.0 2016-01-18 13:38:00  \n",
       "4.0 2016-02-02 12:37:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get num of entries for each id in the training data\n",
    "train_counts = formatter.train_data.groupby('id').count().sort_values('id').iloc[:, 0:1].rename(columns={'time': 'num_test_entries'})\n",
    "\n",
    "# add max time from training to train_counts\n",
    "train_counts['max_time'] = formatter.train_data.groupby('id').max().sort_values('id')['time']\n",
    "\n",
    "# join testing data on ids\n",
    "test_counts = formatter.test_data.groupby('id').count().sort_values('id').iloc[:, 0:1].rename(columns={'time': 'num_test_entries'})\n",
    "test_counts['min_time'] = formatter.test_data.groupby('id').min().sort_values('id')['time']\n",
    "\n",
    "\n",
    "train_counts = train_counts.join(test_counts, how='outer', lsuffix='_train', rsuffix='_test')\n",
    "train_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by patient ID\n",
    "training_data = formatter.train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(data, sequence_length, target_offset=5):\n",
    "    X, y = [], []\n",
    "\n",
    "    for _, group in data.groupby('id'):\n",
    "        group = group.reset_index(drop=True)\n",
    "        gl_series = group['gl'].values\n",
    "        \n",
    "        for i in range(len(gl_series) - sequence_length - target_offset + 1):\n",
    "            X.append(gl_series[i:i+sequence_length])\n",
    "            y.append(gl_series[i + sequence_length:i + sequence_length + target_offset])\n",
    "\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X[..., np.newaxis]  # add channel dimension for Conv1D\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sequence_length = 60  # past 12 time steps (e.g. 1-min intervals for 12 minutes)\n",
    "target_offset = 5     # predict 5 minutes ahead\n",
    "\n",
    "X, y = create_sequences(training_data, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59261, 60, 1), (59261, 5))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Dense, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input((sequence_length, 1)),  # Initial dense layer\n",
    "    Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    GlobalMaxPooling1D(), # Equivalent to flatten\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(target_offset)  # Regression output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 817.0064 - mae: 19.6673 - val_loss: 237.8247 - val_mae: 11.3434\n",
      "Epoch 2/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 336.9629 - mae: 13.4326 - val_loss: 215.2676 - val_mae: 11.0775\n",
      "Epoch 3/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 323.7000 - mae: 13.2534 - val_loss: 207.4446 - val_mae: 10.8252\n",
      "Epoch 4/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 301.6725 - mae: 12.8469 - val_loss: 206.1026 - val_mae: 10.7317\n",
      "Epoch 5/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 287.8028 - mae: 12.5812 - val_loss: 220.8898 - val_mae: 11.4472\n",
      "Epoch 6/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 282.3818 - mae: 12.4746 - val_loss: 206.7636 - val_mae: 11.0631\n",
      "Epoch 7/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 267.4211 - mae: 12.1213 - val_loss: 202.7164 - val_mae: 10.7301\n",
      "Epoch 8/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 273.1788 - mae: 12.2920 - val_loss: 221.4830 - val_mae: 11.3930\n",
      "Epoch 9/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 264.0667 - mae: 12.0277 - val_loss: 214.5698 - val_mae: 11.2358\n",
      "Epoch 10/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 257.5105 - mae: 11.9070 - val_loss: 199.9230 - val_mae: 10.5768\n",
      "Epoch 11/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 253.6916 - mae: 11.8626 - val_loss: 197.1862 - val_mae: 10.5436\n",
      "Epoch 12/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 250.5643 - mae: 11.7543 - val_loss: 206.8962 - val_mae: 11.1224\n",
      "Epoch 13/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 243.6125 - mae: 11.5934 - val_loss: 190.7694 - val_mae: 10.2832\n",
      "Epoch 14/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 249.5534 - mae: 11.7478 - val_loss: 210.0344 - val_mae: 10.8825\n",
      "Epoch 15/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 239.5277 - mae: 11.4769 - val_loss: 193.2068 - val_mae: 10.4073\n",
      "Epoch 16/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 239.0880 - mae: 11.5150 - val_loss: 200.3050 - val_mae: 10.5830\n",
      "Epoch 17/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 236.7151 - mae: 11.3806 - val_loss: 199.3529 - val_mae: 10.6087\n",
      "Epoch 18/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 232.9388 - mae: 11.3072 - val_loss: 227.5138 - val_mae: 11.4137\n",
      "Epoch 19/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 229.7693 - mae: 11.2114 - val_loss: 188.4038 - val_mae: 10.1745\n",
      "Epoch 20/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 235.0100 - mae: 11.2830 - val_loss: 188.7409 - val_mae: 10.2991\n",
      "Epoch 21/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 226.8989 - mae: 11.1413 - val_loss: 197.3819 - val_mae: 10.3925\n",
      "Epoch 22/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 231.3055 - mae: 11.2983 - val_loss: 199.0546 - val_mae: 10.5616\n",
      "Epoch 23/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 220.4707 - mae: 10.9842 - val_loss: 189.4780 - val_mae: 10.2429\n",
      "Epoch 24/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 218.9891 - mae: 10.9443 - val_loss: 191.8532 - val_mae: 10.3598\n",
      "Epoch 25/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 216.9448 - mae: 10.8532 - val_loss: 191.1278 - val_mae: 10.2544\n",
      "Epoch 26/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 219.5066 - mae: 10.9752 - val_loss: 187.1109 - val_mae: 10.1733\n",
      "Epoch 27/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 221.4321 - mae: 10.9881 - val_loss: 216.2415 - val_mae: 11.2359\n",
      "Epoch 28/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 223.2387 - mae: 11.0307 - val_loss: 205.4556 - val_mae: 10.7545\n",
      "Epoch 29/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 216.9127 - mae: 10.8407 - val_loss: 194.1387 - val_mae: 10.3964\n",
      "Epoch 30/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 212.0756 - mae: 10.7139 - val_loss: 192.6653 - val_mae: 10.4766\n",
      "Epoch 31/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 211.4610 - mae: 10.7181 - val_loss: 202.0494 - val_mae: 10.8722\n",
      "Epoch 32/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 212.1098 - mae: 10.7385 - val_loss: 188.8876 - val_mae: 10.0742\n",
      "Epoch 33/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 214.7045 - mae: 10.8345 - val_loss: 193.0695 - val_mae: 10.5116\n",
      "Epoch 34/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 207.2703 - mae: 10.6364 - val_loss: 216.8668 - val_mae: 11.2741\n",
      "Epoch 35/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 216.9920 - mae: 10.8948 - val_loss: 199.7256 - val_mae: 10.7016\n",
      "Epoch 36/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 210.0176 - mae: 10.7211 - val_loss: 189.9178 - val_mae: 10.2005\n",
      "Epoch 37/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 208.7792 - mae: 10.6707 - val_loss: 216.3744 - val_mae: 11.3496\n",
      "Epoch 38/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 210.7336 - mae: 10.6990 - val_loss: 204.9944 - val_mae: 10.9925\n",
      "Epoch 39/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 208.0432 - mae: 10.6706 - val_loss: 187.8439 - val_mae: 10.1841\n",
      "Epoch 40/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 204.6515 - mae: 10.5515 - val_loss: 222.0340 - val_mae: 11.0076\n",
      "Epoch 41/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 200.3258 - mae: 10.4480 - val_loss: 189.7806 - val_mae: 10.3374\n",
      "Epoch 42/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 200.6739 - mae: 10.4250 - val_loss: 194.9358 - val_mae: 10.5229\n",
      "Epoch 43/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 204.2756 - mae: 10.5509 - val_loss: 190.7358 - val_mae: 10.3312\n",
      "Epoch 44/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 198.5958 - mae: 10.3783 - val_loss: 213.0936 - val_mae: 11.2789\n",
      "Epoch 45/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 196.9545 - mae: 10.3511 - val_loss: 181.1405 - val_mae: 9.9345\n",
      "Epoch 46/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 202.6770 - mae: 10.4859 - val_loss: 174.7165 - val_mae: 9.8331\n",
      "Epoch 47/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 198.6855 - mae: 10.3876 - val_loss: 184.0694 - val_mae: 10.1104\n",
      "Epoch 48/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 195.8870 - mae: 10.2644 - val_loss: 185.0323 - val_mae: 10.0574\n",
      "Epoch 49/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 197.6063 - mae: 10.2833 - val_loss: 195.8426 - val_mae: 10.5627\n",
      "Epoch 50/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 195.9233 - mae: 10.2583 - val_loss: 193.1180 - val_mae: 10.4127\n",
      "Epoch 51/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 192.1416 - mae: 10.1846 - val_loss: 181.9080 - val_mae: 9.9432\n",
      "Epoch 52/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 193.7350 - mae: 10.2290 - val_loss: 178.7901 - val_mae: 10.0021\n",
      "Epoch 53/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 189.9931 - mae: 10.1189 - val_loss: 188.3009 - val_mae: 10.1347\n",
      "Epoch 54/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 194.3384 - mae: 10.2021 - val_loss: 186.5213 - val_mae: 10.0205\n",
      "Epoch 55/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 194.7052 - mae: 10.2528 - val_loss: 203.7258 - val_mae: 10.5999\n",
      "Epoch 56/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 193.6721 - mae: 10.2452 - val_loss: 196.2006 - val_mae: 10.5549\n",
      "Epoch 57/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 185.9377 - mae: 10.0398 - val_loss: 213.9494 - val_mae: 11.2156\n",
      "Epoch 58/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 191.4194 - mae: 10.1776 - val_loss: 203.5621 - val_mae: 10.8089\n",
      "Epoch 59/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 191.5276 - mae: 10.1606 - val_loss: 203.4272 - val_mae: 10.6036\n",
      "Epoch 60/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 188.2913 - mae: 10.1017 - val_loss: 223.2557 - val_mae: 11.4920\n",
      "Epoch 61/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 186.4413 - mae: 10.0605 - val_loss: 220.7882 - val_mae: 11.3933\n",
      "Epoch 62/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 188.8169 - mae: 10.0801 - val_loss: 198.0974 - val_mae: 10.6785\n",
      "Epoch 63/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 189.4787 - mae: 10.1081 - val_loss: 194.7768 - val_mae: 10.5753\n",
      "Epoch 64/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 186.1121 - mae: 10.0000 - val_loss: 194.1146 - val_mae: 10.3865\n",
      "Epoch 65/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 187.4569 - mae: 10.0195 - val_loss: 196.3831 - val_mae: 10.5729\n",
      "Epoch 66/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 183.2395 - mae: 9.9620 - val_loss: 184.0960 - val_mae: 10.1587\n",
      "Epoch 67/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 182.4532 - mae: 9.8972 - val_loss: 199.9553 - val_mae: 10.7801\n",
      "Epoch 68/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 181.7257 - mae: 9.9453 - val_loss: 213.5665 - val_mae: 11.0979\n",
      "Epoch 69/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 187.7849 - mae: 10.0610 - val_loss: 186.6442 - val_mae: 10.2916\n",
      "Epoch 70/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 180.1306 - mae: 9.8375 - val_loss: 191.8161 - val_mae: 10.3542\n",
      "Epoch 71/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 182.1415 - mae: 9.9237 - val_loss: 197.8697 - val_mae: 10.5197\n",
      "Epoch 72/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 179.5764 - mae: 9.8158 - val_loss: 229.5931 - val_mae: 11.3832\n",
      "Epoch 73/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 179.2610 - mae: 9.7771 - val_loss: 317.6833 - val_mae: 14.2699\n",
      "Epoch 74/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 178.9305 - mae: 9.8099 - val_loss: 212.5536 - val_mae: 11.2070\n",
      "Epoch 75/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 179.0753 - mae: 9.8344 - val_loss: 190.6790 - val_mae: 10.4696\n",
      "Epoch 76/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 180.5278 - mae: 9.8324 - val_loss: 202.1885 - val_mae: 10.7531\n",
      "Epoch 77/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 181.3949 - mae: 9.8388 - val_loss: 199.3139 - val_mae: 10.6575\n",
      "Epoch 78/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 178.3094 - mae: 9.7787 - val_loss: 207.1792 - val_mae: 10.8369\n",
      "Epoch 79/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 176.5412 - mae: 9.7763 - val_loss: 190.2607 - val_mae: 10.2813\n",
      "Epoch 80/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 177.2268 - mae: 9.7307 - val_loss: 222.9749 - val_mae: 11.4597\n",
      "Epoch 81/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 173.5518 - mae: 9.6319 - val_loss: 206.9934 - val_mae: 10.7479\n",
      "Epoch 82/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 176.1837 - mae: 9.7279 - val_loss: 213.9936 - val_mae: 11.3729\n",
      "Epoch 83/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 172.3041 - mae: 9.6223 - val_loss: 214.7270 - val_mae: 11.1820\n",
      "Epoch 84/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 178.6792 - mae: 9.7951 - val_loss: 212.9618 - val_mae: 11.1055\n",
      "Epoch 85/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 175.2576 - mae: 9.7119 - val_loss: 203.7353 - val_mae: 10.8811\n",
      "Epoch 86/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 171.1006 - mae: 9.6019 - val_loss: 204.2997 - val_mae: 10.8349\n",
      "Epoch 87/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 172.7529 - mae: 9.6472 - val_loss: 199.9820 - val_mae: 10.5220\n",
      "Epoch 88/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 172.7124 - mae: 9.6681 - val_loss: 209.8662 - val_mae: 10.9759\n",
      "Epoch 89/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 169.9072 - mae: 9.5709 - val_loss: 206.3140 - val_mae: 10.8602\n",
      "Epoch 90/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 172.3683 - mae: 9.6216 - val_loss: 207.7899 - val_mae: 10.9404\n",
      "Epoch 91/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 168.5305 - mae: 9.4733 - val_loss: 194.3869 - val_mae: 10.4777\n",
      "Epoch 92/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 167.4944 - mae: 9.4833 - val_loss: 200.8428 - val_mae: 10.6208\n",
      "Epoch 93/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 167.9653 - mae: 9.4850 - val_loss: 222.4829 - val_mae: 11.5943\n",
      "Epoch 94/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 169.0786 - mae: 9.5201 - val_loss: 220.2237 - val_mae: 11.1616\n",
      "Epoch 95/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 163.4523 - mae: 9.3789 - val_loss: 208.2243 - val_mae: 10.9090\n",
      "Epoch 96/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 168.6282 - mae: 9.4610 - val_loss: 221.0100 - val_mae: 11.2501\n",
      "Epoch 97/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 163.2251 - mae: 9.3523 - val_loss: 222.9858 - val_mae: 11.4842\n",
      "Epoch 98/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 168.3276 - mae: 9.5001 - val_loss: 202.4138 - val_mae: 10.7097\n",
      "Epoch 99/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 161.6292 - mae: 9.3026 - val_loss: 229.5770 - val_mae: 11.7033\n",
      "Epoch 100/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 169.0292 - mae: 9.5469 - val_loss: 214.9350 - val_mae: 11.0974\n",
      "Epoch 101/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 165.2455 - mae: 9.3939 - val_loss: 218.7070 - val_mae: 11.0120\n",
      "Epoch 102/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 163.5859 - mae: 9.4020 - val_loss: 212.8331 - val_mae: 10.9799\n",
      "Epoch 103/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 163.3069 - mae: 9.3753 - val_loss: 220.1546 - val_mae: 11.3512\n",
      "Epoch 104/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 161.0865 - mae: 9.3083 - val_loss: 237.5908 - val_mae: 11.7374\n",
      "Epoch 105/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 163.8353 - mae: 9.3665 - val_loss: 211.8875 - val_mae: 11.0484\n",
      "Epoch 106/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 163.5799 - mae: 9.3966 - val_loss: 192.4205 - val_mae: 10.4262\n",
      "Epoch 107/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 159.2759 - mae: 9.2384 - val_loss: 215.6257 - val_mae: 11.0127\n",
      "Epoch 108/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 159.6768 - mae: 9.2902 - val_loss: 212.1375 - val_mae: 10.9661\n",
      "Epoch 109/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 156.6314 - mae: 9.2031 - val_loss: 195.6187 - val_mae: 10.3520\n",
      "Epoch 110/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 159.6619 - mae: 9.2712 - val_loss: 239.3458 - val_mae: 11.8511\n",
      "Epoch 111/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 160.9603 - mae: 9.3118 - val_loss: 235.6379 - val_mae: 11.7413\n",
      "Epoch 112/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 160.0077 - mae: 9.3116 - val_loss: 212.0757 - val_mae: 10.9311\n",
      "Epoch 113/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 155.7003 - mae: 9.1625 - val_loss: 236.0145 - val_mae: 11.8237\n",
      "Epoch 114/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 158.3428 - mae: 9.1858 - val_loss: 203.0707 - val_mae: 10.7089\n",
      "Epoch 115/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 157.5040 - mae: 9.2232 - val_loss: 203.7812 - val_mae: 10.7881\n",
      "Epoch 116/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 153.0144 - mae: 9.1166 - val_loss: 220.6972 - val_mae: 11.2133\n",
      "Epoch 117/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 155.8078 - mae: 9.1659 - val_loss: 280.8862 - val_mae: 12.5804\n",
      "Epoch 118/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 156.9082 - mae: 9.2044 - val_loss: 214.7523 - val_mae: 11.0441\n",
      "Epoch 119/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 153.0875 - mae: 9.0824 - val_loss: 234.0412 - val_mae: 11.5117\n",
      "Epoch 120/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 155.9272 - mae: 9.1583 - val_loss: 268.4716 - val_mae: 12.5866\n",
      "Epoch 121/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 155.4985 - mae: 9.1506 - val_loss: 225.9458 - val_mae: 11.3192\n",
      "Epoch 122/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 154.3004 - mae: 9.1208 - val_loss: 232.8866 - val_mae: 11.6717\n",
      "Epoch 123/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 153.0582 - mae: 9.1246 - val_loss: 224.1588 - val_mae: 11.2678\n",
      "Epoch 124/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 152.5526 - mae: 9.0322 - val_loss: 234.4614 - val_mae: 11.6854\n",
      "Epoch 125/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 152.9726 - mae: 9.0777 - val_loss: 231.0985 - val_mae: 11.3726\n",
      "Epoch 126/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 152.7568 - mae: 9.0612 - val_loss: 222.6845 - val_mae: 11.3058\n",
      "Epoch 127/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 151.0947 - mae: 9.0543 - val_loss: 222.6949 - val_mae: 11.2262\n",
      "Epoch 128/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 150.2381 - mae: 8.9665 - val_loss: 220.2914 - val_mae: 11.1802\n",
      "Epoch 129/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 146.5649 - mae: 8.8937 - val_loss: 212.5455 - val_mae: 11.0168\n",
      "Epoch 130/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 152.3529 - mae: 9.0316 - val_loss: 219.2215 - val_mae: 11.1606\n",
      "Epoch 131/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 148.4890 - mae: 8.9299 - val_loss: 262.0566 - val_mae: 12.5580\n",
      "Epoch 132/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 152.6928 - mae: 9.0748 - val_loss: 211.1850 - val_mae: 10.8796\n",
      "Epoch 133/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 148.7596 - mae: 8.9293 - val_loss: 233.4948 - val_mae: 11.7439\n",
      "Epoch 134/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 146.7013 - mae: 8.9188 - val_loss: 209.6651 - val_mae: 10.6929\n",
      "Epoch 135/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 146.3172 - mae: 8.8635 - val_loss: 222.7470 - val_mae: 11.0607\n",
      "Epoch 136/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 149.0959 - mae: 8.9227 - val_loss: 226.9459 - val_mae: 11.3542\n",
      "Epoch 137/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 148.7814 - mae: 8.9309 - val_loss: 228.9047 - val_mae: 11.3653\n",
      "Epoch 138/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 145.2390 - mae: 8.8473 - val_loss: 224.7169 - val_mae: 11.1870\n",
      "Epoch 139/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 146.8243 - mae: 8.8960 - val_loss: 232.3930 - val_mae: 11.6077\n",
      "Epoch 140/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 144.5149 - mae: 8.8064 - val_loss: 223.5187 - val_mae: 11.3232\n",
      "Epoch 141/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 143.8648 - mae: 8.8279 - val_loss: 262.9258 - val_mae: 12.6242\n",
      "Epoch 142/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 149.2951 - mae: 8.9574 - val_loss: 219.9737 - val_mae: 11.0558\n",
      "Epoch 143/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 143.6948 - mae: 8.8006 - val_loss: 240.2535 - val_mae: 11.6543\n",
      "Epoch 144/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 143.6003 - mae: 8.7988 - val_loss: 237.3735 - val_mae: 11.7159\n",
      "Epoch 145/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 140.9412 - mae: 8.7380 - val_loss: 238.5679 - val_mae: 11.6976\n",
      "Epoch 146/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 142.3589 - mae: 8.7269 - val_loss: 226.9359 - val_mae: 11.4121\n",
      "Epoch 147/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 140.5540 - mae: 8.6814 - val_loss: 216.2384 - val_mae: 10.9317\n",
      "Epoch 148/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 147.1095 - mae: 8.8669 - val_loss: 248.7078 - val_mae: 11.9246\n",
      "Epoch 149/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 142.5014 - mae: 8.7825 - val_loss: 238.8377 - val_mae: 11.6594\n",
      "Epoch 150/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 139.5556 - mae: 8.6778 - val_loss: 252.9581 - val_mae: 11.9627\n",
      "Epoch 151/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 139.9276 - mae: 8.7121 - val_loss: 224.5211 - val_mae: 11.2218\n",
      "Epoch 152/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 143.3447 - mae: 8.7591 - val_loss: 237.7086 - val_mae: 11.6629\n",
      "Epoch 153/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 138.5034 - mae: 8.6449 - val_loss: 241.1254 - val_mae: 11.6704\n",
      "Epoch 154/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 142.6062 - mae: 8.7464 - val_loss: 236.5814 - val_mae: 11.4416\n",
      "Epoch 155/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 136.4817 - mae: 8.5473 - val_loss: 274.5997 - val_mae: 12.4415\n",
      "Epoch 156/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 138.6567 - mae: 8.6903 - val_loss: 240.9315 - val_mae: 11.6539\n",
      "Epoch 157/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 138.0230 - mae: 8.6158 - val_loss: 241.0022 - val_mae: 11.6122\n",
      "Epoch 158/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 138.3487 - mae: 8.6188 - val_loss: 234.5667 - val_mae: 11.3374\n",
      "Epoch 159/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 133.6761 - mae: 8.4851 - val_loss: 293.7307 - val_mae: 12.8541\n",
      "Epoch 160/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 138.3940 - mae: 8.6389 - val_loss: 245.5697 - val_mae: 11.6944\n",
      "Epoch 161/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 137.6808 - mae: 8.6062 - val_loss: 241.5303 - val_mae: 11.6267\n",
      "Epoch 162/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 139.3719 - mae: 8.6739 - val_loss: 231.9997 - val_mae: 11.3288\n",
      "Epoch 163/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 138.3348 - mae: 8.6018 - val_loss: 234.8674 - val_mae: 11.1927\n",
      "Epoch 164/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 136.0556 - mae: 8.5633 - val_loss: 232.0828 - val_mae: 11.3823\n",
      "Epoch 165/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 136.5129 - mae: 8.5611 - val_loss: 291.3811 - val_mae: 12.8524\n",
      "Epoch 166/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 136.4607 - mae: 8.5937 - val_loss: 263.6262 - val_mae: 12.1563\n",
      "Epoch 167/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 135.2987 - mae: 8.5080 - val_loss: 247.6648 - val_mae: 11.6156\n",
      "Epoch 168/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 136.4084 - mae: 8.5593 - val_loss: 235.8526 - val_mae: 11.4577\n",
      "Epoch 169/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 136.3076 - mae: 8.5729 - val_loss: 252.8350 - val_mae: 11.7241\n",
      "Epoch 170/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 134.3637 - mae: 8.4734 - val_loss: 247.8475 - val_mae: 11.5952\n",
      "Epoch 171/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 132.5435 - mae: 8.4774 - val_loss: 245.3428 - val_mae: 11.6985\n",
      "Epoch 172/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 137.6835 - mae: 8.6004 - val_loss: 240.7101 - val_mae: 11.5127\n",
      "Epoch 173/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 133.3318 - mae: 8.4675 - val_loss: 250.7913 - val_mae: 11.8085\n",
      "Epoch 174/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 131.9810 - mae: 8.4498 - val_loss: 244.5569 - val_mae: 11.6755\n",
      "Epoch 175/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 131.4909 - mae: 8.4065 - val_loss: 248.5369 - val_mae: 11.7132\n",
      "Epoch 176/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 131.6308 - mae: 8.3877 - val_loss: 250.7675 - val_mae: 11.8192\n",
      "Epoch 177/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 133.5284 - mae: 8.4212 - val_loss: 258.5945 - val_mae: 11.9599\n",
      "Epoch 178/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 130.2865 - mae: 8.3850 - val_loss: 244.7515 - val_mae: 11.5882\n",
      "Epoch 179/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 132.7200 - mae: 8.4535 - val_loss: 245.5012 - val_mae: 11.7427\n",
      "Epoch 180/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 130.2811 - mae: 8.3762 - val_loss: 237.9965 - val_mae: 11.4671\n",
      "Epoch 181/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 129.6599 - mae: 8.3385 - val_loss: 278.3864 - val_mae: 12.5764\n",
      "Epoch 182/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 130.0358 - mae: 8.3733 - val_loss: 248.6920 - val_mae: 11.7924\n",
      "Epoch 183/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 132.2779 - mae: 8.4333 - val_loss: 240.3818 - val_mae: 11.3509\n",
      "Epoch 184/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 130.6082 - mae: 8.3857 - val_loss: 235.2734 - val_mae: 11.4848\n",
      "Epoch 185/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 128.8740 - mae: 8.3166 - val_loss: 272.0031 - val_mae: 12.5349\n",
      "Epoch 186/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 128.7473 - mae: 8.3469 - val_loss: 280.4046 - val_mae: 12.8313\n",
      "Epoch 187/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 130.1240 - mae: 8.3755 - val_loss: 245.1614 - val_mae: 11.8219\n",
      "Epoch 188/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 126.1058 - mae: 8.2634 - val_loss: 273.3759 - val_mae: 12.6155\n",
      "Epoch 189/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 125.5834 - mae: 8.2342 - val_loss: 261.0594 - val_mae: 11.9425\n",
      "Epoch 190/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 126.9326 - mae: 8.2574 - val_loss: 258.9660 - val_mae: 12.1345\n",
      "Epoch 191/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 127.2512 - mae: 8.2809 - val_loss: 270.6209 - val_mae: 12.2827\n",
      "Epoch 192/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 126.0640 - mae: 8.2568 - val_loss: 261.2570 - val_mae: 12.0545\n",
      "Epoch 193/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 126.0781 - mae: 8.2445 - val_loss: 286.3124 - val_mae: 13.0819\n",
      "Epoch 194/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 128.3219 - mae: 8.3174 - val_loss: 254.7787 - val_mae: 11.8607\n",
      "Epoch 195/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 125.6782 - mae: 8.2301 - val_loss: 270.6144 - val_mae: 12.5464\n",
      "Epoch 196/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 124.8976 - mae: 8.2003 - val_loss: 289.0941 - val_mae: 12.8321\n",
      "Epoch 197/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 123.8965 - mae: 8.1949 - val_loss: 303.9035 - val_mae: 13.2297\n",
      "Epoch 198/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 125.7579 - mae: 8.2044 - val_loss: 271.1122 - val_mae: 12.3021\n",
      "Epoch 199/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 123.8913 - mae: 8.1758 - val_loss: 245.5186 - val_mae: 11.6108\n",
      "Epoch 200/200\n",
      "\u001b[1m1482/1482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 126.1703 - mae: 8.2325 - val_loss: 298.5357 - val_mae: 12.8450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e9a5016950>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the test data\n",
    "test_data = formatter.test_data[~formatter.test_data.index.isin(formatter.test_idx_ood)]\n",
    "X_test, y_test = create_sequences(test_data, sequence_length, target_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step\n",
      "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 284.1903 - mae: 12.4656\n",
      "Test loss: [274.4681396484375, 11.954923629760742]\n"
     ]
    }
   ],
   "source": [
    "# predictions go here\n",
    "prediction = model.predict(X_test)\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 1), (5,), (5,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test[0].shape, y_test[0].shape, prediction[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Predictions within a Window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
